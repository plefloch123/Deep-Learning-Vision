{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVYtNKvZuW4y"
   },
   "source": [
    "# Coursework 1: Convolutional Neural Networks \n",
    "### Autograding\n",
    "Part 1 of this coursework is autograded. This notebook comes with embedded tests which will verify that your implementations provide outputs with the appropriate types and shapes required for our hidden tests. You can run these same public tests through [LabTS](https://teaching.doc.ic.ac.uk/labts) when you have finished your work, to check that we get the same results when running these public tests.\n",
    "\n",
    "Hidden tests will be ran after the submission deadline, and cannot be accessed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up working environment \n",
    "\n",
    "For this coursework you will need to train a large network, therefore we recommend you work with the Lab cluster or (if need be) Google Colab, where you can access GPUs.\n",
    "\n",
    "Please refer to the Intro lecture for getting set up on the various GPU options.\n",
    "\n",
    "**To work on the coursework on DoC lab machines** you will need to correctly set the `USERNAME` variable in the initialization cell below and place the coursework files in the directory specified by the `content_path` variable (or directly adjust `content_path` to point to the saved coursework files). We recommend placing these files on `/vol/bitbucket` instead of your home folder, otherwise you may quickly deplete your [DoC quota](https://www.imperial.ac.uk/computing/people/csg/guides/file-storage/quota/). You should also setup a [Python virtual environment](https://docs.python.org/3/library/venv.html) with [Jupyter Lab](https://jupyter.org/install) that you can use for running this notebook (you don't need to install any other packages, as they will be installed automatically by the code below — just make sure to run the notebook with the correct virtual environment active).\n",
    "\n",
    "**To work on the coursework within Colab** you will need to copy the coursework files to your Google Drive and place them in the directory specified by the `dl_cw1_repo_path` variable in the initialization cell below. Due to degraded performance when working with large datasets on Google Colab, we strongly recommend using the lab machines or the GPU cluster for working on Part 2 of the coursework whenever possible. If you still wish to use Google Colab, we recommend performing the data preprocessing for Part 2 locally or on a lab machine and only using Colab for model training and adjustments. See the instructions for Part 2 for details. Note that reading data from Google Drive is likely to considerably slow down the training in the following steps.\n",
    "\n",
    "#### Setup\n",
    "You will need to install pytorch and other libraries by running the following cells:\n",
    "\n",
    "<font color=\"orange\">**The deadline for submission is Friday, 31 Jan by 6 pm** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 10), f\"Python 3.10 or higher is required for this coursework, but you are using {sys.version}. Please use a more recent Python version or you might face compatibility issues.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53jMRaMRuW4_",
    "outputId": "fcbde88b-d4cb-4e65-83d7-8afe555c3448"
   },
   "outputs": [],
   "source": [
    "# Initialization Cell\n",
    "import traceback\n",
    "try:\n",
    "    import os\n",
    "    WORKING_ENV = 'LABS' # Can be LABS, COLAB\n",
    "    USERNAME = 'your_username' # If working on Lab machines, set your College username\n",
    "    assert WORKING_ENV in ['LABS', 'COLAB']\n",
    "\n",
    "    if WORKING_ENV == 'COLAB':\n",
    "        # Need to change to some writeable directory for the grader to run correctly\n",
    "        home_directory = os.path.expanduser(\"~\")\n",
    "        os.chdir(home_directory)\n",
    "        from google.colab import drive\n",
    "        %load_ext google.colab.data_table\n",
    "        d1_cw1_repo_path = 'dl_cw_1/' # path in your gdrive to the repo\n",
    "        content_path = f'/content/drive/MyDrive/{d1_cw1_repo_path}' # path to gitrepo in gdrive after mounting\n",
    "        drive.mount('/content/drive/') # Outputs will be saved in your google drive\n",
    "    elif WORKING_ENV == 'LABS':\n",
    "        content_path = f'/vol/bitbucket/{USERNAME}/dl_cw_1/' # You may want to change this\n",
    "        # Your python env and training data should be on bitbucket\n",
    "        print('Storing big data in ', content_path)\n",
    "        if 'vol' not in content_path:\n",
    "            import warnings\n",
    "            warnings.warn(\n",
    "                'It is best to create a dir in /vol/bitbucket/ otherwise you will quickly run into memory issues'\n",
    "            )\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    if not os.path.exists(f'{content_path}'):\n",
    "        raise ValueError('Cannot locate the specified content path.')\n",
    "    if not os.path.exists(f'{content_path}/requirements.txt'):\n",
    "        raise ValueError(\"Cannot locate requirements.txt file on the specified content path.\")\n",
    "    print(\"Installing dependencies...\")\n",
    "    %pip install -q -r {content_path}/requirements.txt\n",
    "    if not os.path.exists(os.path.join(content_path, 'icl_dl_cw2_utils')):\n",
    "        !git clone -q https://github.com/bkainz/icl_dl_cw2_utils {content_path}/icl_dl_cw2_utils\n",
    "    print(\"Done!\")\n",
    "    import otter\n",
    "    grader = otter.Notebook(\n",
    "        os.path.join(content_path, 'dl_cw_1.ipynb'),\n",
    "        tests_dir=os.path.join(content_path, 'tests')\n",
    "    )\n",
    "    import matplotlib.pyplot as plt # DO NOT use %matplotlib inline in the notebook\n",
    "    import numpy as np\n",
    "    rng_seed = 90\n",
    "    print(\"Initialization successful!\")\n",
    "except:\n",
    "    # This is a fallback initialization for running on LabTS. Please leave this in place before submission.\n",
    "    print(\"Running fallback LabTS initialisation due to the following exception:\")\n",
    "    traceback.print_exc()\n",
    "    import otter\n",
    "    grader = otter.Notebook(\"dl_cw_1.ipynb\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    rng_seed = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9Wj8-TMuW5I"
   },
   "source": [
    "## Introduction\n",
    "In this courswork you will explore various deep learning functionalities through implementing a number of pytorch neural network operations/layers and creating your own deep learning model and methodology for a high dimensional classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FjLiYiIuW5K"
   },
   "source": [
    "#### Intended learning outcomes\n",
    "- An understanding of the mechanics behind convolutional, pooling, linear and batch norm operations. \n",
    "- Be able to implement convolution, pooling, linear and batch norm layers from basic building blocks.\n",
    "- Experience designing, implementing and optimising a classifier for a high dimensional dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RA-GseZuW5Q"
   },
   "source": [
    "## Part 1 (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OplG2ZNZuW5S"
   },
   "source": [
    "In this part, you will use basic Pytorch operations to define the 2D convolution, 2D max pooling, linear layer, as well as 2D batch normalization operations. Being computer scientists we care about efficiency, we therefore do not want to see any _for loops_!\n",
    "\n",
    "**Your Task**\n",
    "- Implement the forward pass for Conv2D (15 points), MaxPool2D (15 points), Linear (5 points) and BatchNorm2d (15 points)\n",
    "- You are **NOT** allowed to use the torch.nn modules (the one exception is that the class inherits from nn.Module), F.conv2d, F.max_pool2d, F.linear, F.batch_norm or similar high-level PyTorch functions. Feel free to use base operations like transpose and matmul though.\n",
    "\n",
    "_hint: Check out F.unfold and F.fold — these are allowed and may be helpful._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2FymI-duW5W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 bias=True):\n",
    "\n",
    "        super(Conv2d, self).__init__()\n",
    "        \"\"\"\n",
    "        An implementation of a convolutional layer.\n",
    "\n",
    "        The input consists of N data points, each with C channels, height H and\n",
    "        width W. We convolve each input with F different filters, where each filter\n",
    "        spans all C channels and has height H' and width W'.\n",
    "\n",
    "        Parameters:\n",
    "        - kernel_size: Union[int, (int, int)], Size of the convolving kernel\n",
    "        - stride: Union[int, (int, int)], Number of pixels between adjacent receptive fields in the\n",
    "            horizontal and vertical directions.\n",
    "        - padding: Union[int, (int, int)], Number of pixels that will be used to zero-pad the input.\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # TODO: Define the parameters used in the forward pass\n",
    "        ...\n",
    "        # Do not initialize weights or biases with torch.empty() but rather use torch.randn()\n",
    "        # Weights should have shape [out_channels, in_channels, kernel_x, kernel_y]\n",
    "        self.w = ...\n",
    "        # Bias should have shape [out_channels] \n",
    "        self.b = ...\n",
    "        self.F = ...\n",
    "        self.C = ...\n",
    "        self.kernel_size = ...\n",
    "        self.stride = ...\n",
    "        self.padding = ...\n",
    "        ...\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        - x: Input data of shape (N, C, H, W)\n",
    "        Output:\n",
    "        - out: Output data, of shape (N, F, H', W').\n",
    "        \"\"\"\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # TODO: Implement the forward pass                                     #\n",
    "        ...\n",
    "        out = ...\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Convolution Layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThrRIjf9uW5a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxPool2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MaxPool2d, self).__init__()\n",
    "        \"\"\"\n",
    "        An implementation of a max-pooling layer without padding\n",
    "\n",
    "        Parameters:\n",
    "        - kernel_size: Union[int, (int, int)], the size of the window\n",
    "        to take a max over, also equal to the stride\n",
    "        \"\"\"\n",
    "        # TODO: Define the parameters used in the forward pass                 #\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        ...\n",
    "        self.kernel_size = ...\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        - x: Input data of shape (N, C, H, W)\n",
    "        Output:\n",
    "        - out: Output data, of shape (N, C, H', W').\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass                                     #\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ...\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"MaxPool Layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4jqNUbguW5d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        \"\"\"\n",
    "        An implementation of a Linear layer.\n",
    "\n",
    "        Parameters:\n",
    "        - weight: the learnable weights of the module of shape (in_channels, out_channels).\n",
    "        - bias: the learnable bias of the module of shape (out_channels).\n",
    "        \"\"\"\n",
    "        # TODO: Define the parameters used in the forward pass                 #\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        self.w = ...\n",
    "        self.b = ...\n",
    "        ...\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        - x: Input data of shape (N, *, H) where * means any number of additional\n",
    "        dimensions and H = in_channels\n",
    "        Output:\n",
    "        - out: Output data of shape (N, *, H') where * means any number of additional\n",
    "        dimensions and H' = out_channels\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass                                     #\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ...\n",
    "        \n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Linear Layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je2rfaENuW5f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNorm2d(nn.Module):\n",
    "\tdef __init__(self, num_features, eps=1e-05, momentum=0.1):\n",
    "\t\tsuper(BatchNorm2d, self).__init__()\n",
    "\t\t\"\"\"\n",
    "\t\tAn implementation of a Batch Normalization over a mini-batch of 2D inputs.\n",
    "\n",
    "\t\tThe mean and standard-deviation are calculated per-dimension over the\n",
    "\t\tmini-batches and gamma and beta are learnable parameter vectors of\n",
    "\t\tsize num_features.\n",
    "\n",
    "\t\tParameters:\n",
    "\t\t- num_features: C from an expected input of size (N, C, H, W).\n",
    "\t\t- eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
    "\t\t- momentum: the value used for the running_mean and running_var\n",
    "\t\tcomputation. Default: 0.1 . (i.e. 1-momentum for running mean)\n",
    "\t\t- gamma: the learnable weights of shape (num_features).\n",
    "\t\t- beta: the learnable bias of the module of shape (num_features).\n",
    "\t\t\"\"\"\n",
    "\t\t# TODO: Define the parameters used in the forward pass                 #\n",
    "\t\t# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\t\tself.num_features = ...\n",
    "\t\tself.eps = ...\n",
    "\t\tself.momentum = ...\n",
    "\n",
    "\t\t# self.register_parameter is not used as it was mentioned on piazza\n",
    "\t\t# that this will be overridden\n",
    "\t\tself.gamma = ...\n",
    "\t\tself.beta = ...\n",
    "\t\t...\n",
    "\t\t# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t\"\"\"\n",
    "\t\tDuring training this layer keeps running estimates of its computed mean and\n",
    "\t\tvariance, which are then used for normalization during evaluation.\n",
    "\t\tInput:\n",
    "\t\t- x: Input data of shape (N, C, H, W)\n",
    "\t\tOutput:\n",
    "\t\t- out: Output data of shape (N, C, H, W) (same shape as input)\n",
    "\t\t\"\"\"\n",
    "\t\t# TODO: Implement the forward pass                                     #\n",
    "\t\t#       (be aware of the difference for training and testing)          #\n",
    "\t\t# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\t\t...\n",
    "\t\t# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"BatchNorm Layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMQSFRNUuW5i"
   },
   "source": [
    "## Part 2 (39 points) \n",
    "\n",
    "In this part, you will design, train, and optimize a custom deep learning model for classifying the Food-101 dataset. This dataset, widely used for food classification tasks, contains 101 classes representing a diverse range of popular dishes from around the world. We believe this dataset will be both engaging and challenging, providing an opportunity to work on a real-world application of computer vision in food recognition.\n",
    "\n",
    "You will be marked on your experimental process, methods implemented and your reasoning behind your decisions. While there will be marks for exceeding a baseline performance score we stress that students should **NOT** spend excessive amounts of time optimising performance to silly levels.\n",
    "\n",
    "We have given you some starter code, please feel free to use and adapt it.\n",
    "\n",
    "**Your Task**\n",
    "1. Develop/adapt a deep learning pipeline to maximise performance on the test set. (34 points)\n",
    "    * 12 points will be awarded for improving on the baseline score on the test set. Don't worry you can get full marks here by improving by a minor amount.\n",
    "    * 22 points will be awarded for the adaptations made to the baseline model and pipeline.\n",
    "\n",
    "2. Answer the qualititative questions (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfh7tCyXUoTo"
   },
   "source": [
    "**Downloading food-101 dataset**\n",
    "\n",
    "**Note:** You should only need to run the downloading and data processing code once. If you are using **Colab**, please run this code locally (or on lab machines) and upload the preprocessed files to your Google Drive manually (you should only need the files in the `train` and `test` subfolders). If you try to run the below code directly on Colab, you may encounter [issues with syncing the files](https://github.com/googlecolab/colabtools/issues/287) (even if you use `drive.flush_and_unmount()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsLO9QDMUoTo",
    "outputId": "969cc6f4-1d9a-4ffc-ff74-c07a27c65883",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Helper function to download data and extract\n",
    "import os\n",
    "def get_data_extract():\n",
    "  if \"food-101\" in os.listdir(content_path):\n",
    "    print(\"Dataset already exists\")\n",
    "  else:\n",
    "    print(\"Downloading the data...\")\n",
    "    if not os.path.exists(os.path.join(content_path, 'food-101.tar.gz')):\n",
    "        !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "    print(\"Dataset downloaded!\")\n",
    "    print(\"Extracting data..\")\n",
    "    os.makedirs(content_path, exist_ok=True)\n",
    "    !tar xzvf food-101.tar.gz -C \"{content_path}\" | awk '/\\/$/'\n",
    "    print(\"Extraction done!\")\n",
    "\n",
    "assert WORKING_ENV != 'COLAB', \"If you are using Colab, please download and preprocess the files locally — see the instructions above.\"\n",
    "\n",
    "# Download data and extract it to folder\n",
    "get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Helper method to split dataset into train and test folders\n",
    "from shutil import copy\n",
    "def prepare_data(filepath, src,dest):\n",
    "  classes_images = defaultdict(list)\n",
    "  with open(filepath, 'r') as txt:\n",
    "      paths = [read.strip() for read in txt.readlines()]\n",
    "      for p in paths:\n",
    "        food = p.split('/')\n",
    "        classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "  for food in classes_images.keys():\n",
    "    print(\"\\nCopying images into \",food)\n",
    "    if not os.path.exists(os.path.join(dest,food)):\n",
    "      os.makedirs(os.path.join(dest,food))\n",
    "    for i in classes_images[food]:\n",
    "      if os.path.exists(os.path.join(dest, food, i)):\n",
    "        continue\n",
    "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "  print(\"Copying Done!\")\n",
    "  \n",
    "data_path = content_path + '/food-101/'\n",
    "  \n",
    "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
    "print(\"Creating training data...\")\n",
    "prepare_data(data_path+'meta/train.txt', data_path+'images', data_path+'train')\n",
    "\n",
    "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
    "print(\"Creating test data...\")\n",
    "prepare_data(data_path+'meta/test.txt', data_path+'images', data_path+'test')\n",
    "\n",
    "# Check how many files are in the train folder\n",
    "print(\"Total number of samples in train folder\")\n",
    "train_path = data_path+'train'\n",
    "!find \"{train_path}\" -type d -or -type f -printf '.' | wc -c\n",
    "\n",
    "# Check how many files are in the test folder\n",
    "print(\"Total number of samples in test folder\")\n",
    "test_path = data_path+'test'\n",
    "!find \"{test_path}\" -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Im6LzJJ6uW5o",
    "outputId": "d132776c-01ed-4231-d9d2-77fa86f7f639",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "#other\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# set the seed for reproducibility\n",
    "rng_seed = 90\n",
    "torch.manual_seed(rng_seed)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XuC3wCSUoTp",
    "outputId": "1d3c1fc3-03ad-42a3-c108-de12a6f993c7",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# When we import the images we want to first convert them to a tensor. \n",
    "# It is also common in deep learning to normalise the the inputs. This \n",
    "# helps with stability.\n",
    "# To read more about this subject this article is a great one:\n",
    "# https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0\n",
    "\n",
    "# transforms is a useful pytorch package which contains a range of functions\n",
    "# for preprocessing data, for example applying data augmentation to images \n",
    "# (random rotations, blurring the image, randomly cropping the image). To find out\n",
    "# more please refer to the pytorch documentation:\n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406])\n",
    "std = torch.Tensor([0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean.tolist(), std.tolist()),\n",
    "        ]\n",
    "    )\n",
    "train_path = content_path+'/food-101/train'\n",
    "test_path = content_path+'/food-101/test'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# Create train val split\n",
    "n = len(train_dataset)\n",
    "n_val = int(n/10)\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [n-n_val, n_val])\n",
    "\n",
    "\n",
    "print(len(train_set), len(val_set), len(test_dataset))\n",
    "\n",
    "\n",
    "# The number of images to process in one go. If you run out of GPU\n",
    "# memory reduce this number! \n",
    "batch_size = 128\n",
    "\n",
    "# Dataloaders are a great pytorch functionality for feeding data into our AI models.\n",
    "# see https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
    "# for more info.\n",
    "\n",
    "def get_num_workers():\n",
    "    suggested_workers = 0\n",
    "    if hasattr(os, 'sched_getaffinity'):\n",
    "        try:\n",
    "            suggested_workers = len(os.sched_getaffinity(0))\n",
    "        except Exception:\n",
    "            pass\n",
    "    if suggested_workers == 0:\n",
    "        cpu_count = os.cpu_count()\n",
    "        if cpu_count is not None:\n",
    "            suggested_workers = cpu_count\n",
    "    num_workers = min(8, suggested_workers)\n",
    "    return num_workers\n",
    "\n",
    "num_workers = get_num_workers()\n",
    "print(f\"Using {num_workers} workers\")\n",
    "loader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "loader_val = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwxm3jsxUoTq",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist())\n",
    "\n",
    "def denorm(x):\n",
    "    '''\n",
    "    Function to reverse the normalization so that we can visualise the outputs\n",
    "    '''\n",
    "    x = unnormalize(x)\n",
    "    x = x.view(x.size(0), 3, 256, 256)\n",
    "    return x\n",
    "\n",
    "def show(img):\n",
    "    '''\n",
    "    function to visualise tensors\n",
    "    '''\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cpu()\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)).clip(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gLtEaOIUoTq"
   },
   "source": [
    "**Visualising some example images** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "MtlftLPjUoTq",
    "outputId": "1355c6ee-3175-43bf-e916-fb18156c5f47",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "sample_inputs, _ = next(iter(loader_val))\n",
    "fixed_input = sample_inputs[:27, :, :, :]\n",
    "\n",
    "img = make_grid(denorm(fixed_input), nrow=9, padding=2, normalize=False,\n",
    "                value_range=None, scale_each=False, pad_value=0)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis('off')\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define ResNet-18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bknm_PrxuW5r",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# define resnet building blocks\n",
    "\n",
    "class ResidualBlock(nn.Module): \n",
    "    def __init__(self, inchannel, outchannel, stride=1): \n",
    "        \n",
    "        super(ResidualBlock, self).__init__() \n",
    "        \n",
    "        self.left = nn.Sequential(nn.Conv2d(inchannel, outchannel, kernel_size=3, \n",
    "                                         stride=stride, padding=1, bias=False), \n",
    "                                  nn.BatchNorm2d(outchannel), \n",
    "                                  nn.ReLU(inplace=True), \n",
    "                                  nn.Conv2d(outchannel, outchannel, kernel_size=3, \n",
    "                                         stride=1, padding=1, bias=False), \n",
    "                                  nn.BatchNorm2d(outchannel)) \n",
    "        \n",
    "        self.shortcut = nn.Sequential() \n",
    "        \n",
    "        if stride != 1 or inchannel != outchannel: \n",
    "            \n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(inchannel, outchannel, \n",
    "                                                 kernel_size=1, stride=stride, \n",
    "                                                 padding = 0, bias=False), \n",
    "                                          nn.BatchNorm2d(outchannel) ) \n",
    "            \n",
    "    def forward(self, x): \n",
    "        \n",
    "        out = self.left(x) \n",
    "        \n",
    "        out += self.shortcut(x) \n",
    "        \n",
    "        out = F.relu(out) \n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "# define resnet\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, ResidualBlock, num_classes = 101):\n",
    "        \n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.inchannel = 16\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 16, kernel_size = 3, stride = 1,\n",
    "                                            padding = 1, bias = False), \n",
    "                                  nn.BatchNorm2d(16), \n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        self.layer1 = self.make_layer(ResidualBlock, 16, 2, stride = 2)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 32, 2, stride = 2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 64, 2, stride = 2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 128, 2, stride = 2)\n",
    "        self.layer5 = self.make_layer(ResidualBlock, 256, 2, stride = 2)\n",
    "        self.layer6 = self.make_layer(ResidualBlock, 512, 2, stride = 2)\n",
    "        self.maxpool = nn.MaxPool2d(4)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for stride in strides:\n",
    "            \n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            \n",
    "            self.inchannel = channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# please do not change the name of this class\n",
    "def MyResNet():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ujAcIPbix75",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def confusion(preds, y):\n",
    "  with open(content_path+'/food-101/meta/labels.txt', 'r') as file:\n",
    "        labels = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "  # Plotting the confusion matrix\n",
    "  cm = confusion_matrix(y.cpu().numpy(), preds.cpu().numpy(), normalize='true', labels=range(len(labels)))\n",
    "  fig, ax= plt.subplots(1, 1, figsize=(55,50))\n",
    "  sns.heatmap(cm, annot=True, annot_kws={\"size\": 8}, ax=ax, cmap=\"Blues\")\n",
    "\n",
    "  # labels, title and ticks\n",
    "  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "  ax.set_title('Confusion Matrix');\n",
    "  ax.set_xticks(range(len(labels)), labels=labels); ax.set_yticks(range(len(labels)), labels=labels);\n",
    "  ax.xaxis.set_ticklabels(labels, rotation = 90); ax.yaxis.set_ticklabels(labels, rotation=0);\n",
    "  plt.show()\n",
    "\n",
    "def incorrect_preds(preds, y, test_img):\n",
    "  with open(content_path+'/food-101/meta/labels.txt', 'r') as file:\n",
    "        labels = [line.strip() for line in file if line.strip()]\n",
    "  # lets see a sample of the images which were classified incorrectly!\n",
    "  correct = (preds == y).float()\n",
    "  test_labels_check = correct.cpu().numpy()\n",
    "  incorrect_indexes = np.where(test_labels_check == 0)\n",
    "\n",
    "  test_img = test_img.cpu()\n",
    "  samples = make_grid(denorm(test_img[incorrect_indexes][:9]), nrow=3,\n",
    "                      padding=2, normalize=False, value_range=None, \n",
    "                      scale_each=False, pad_value=0)\n",
    "  plt.figure(figsize = (20,10))\n",
    "  plt.title('Incorrectly Classified Instances')\n",
    "  show(samples)\n",
    "  labels = np.asarray(labels)\n",
    "  print('Predicted label',labels[preds[incorrect_indexes].cpu().numpy()[:9]])\n",
    "  print('True label', labels[y[incorrect_indexes].cpu().numpy()[:9]])\n",
    "  print('Corresponding images are shown below')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AynHSTv3uW55",
    "outputId": "f018a4a0-b5b5-4bd0-a3cb-9593750e0d60",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 \n",
    "\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "    \n",
    "\n",
    "print_every = 10\n",
    "def check_accuracy(loader, model, analysis=False, hotdog_data=False):\n",
    "    # function for test accuracy on validation and test set\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    target_class_correct = 0\n",
    "    target_class_samples = 0\n",
    "    target_class = 55 #hot dogs\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device\n",
    "            if hotdog_data:\n",
    "                y = torch.tensor(target_class).repeat(x.shape[0]).to(device=device, dtype=torch.long)\n",
    "            else:\n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            mask = (y == target_class)  # Filter for target class\n",
    "            if mask.sum() > 0:  # Ensure there are samples of the target class\n",
    "                target_class_correct += (preds[mask] == y[mask]).sum()\n",
    "                target_class_samples += mask.sum()\n",
    "                \n",
    "            if t == 0 and analysis:\n",
    "              stack_labels = y\n",
    "              stack_predicts = preds\n",
    "            elif analysis:\n",
    "              stack_labels = torch.cat([stack_labels, y], 0)\n",
    "              stack_predicts = torch.cat([stack_predicts, preds], 0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct of val set (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        \n",
    "        # Calculate accuracy for the target class\n",
    "        if target_class_samples > 0:\n",
    "            target_class_acc = float(target_class_correct) / target_class_samples\n",
    "            print('Got %d / %d correct Hot Dogs (class %d) (%.2f%%)' % (\n",
    "                target_class_correct, target_class_samples, target_class, 100 * target_class_acc))\n",
    "        else:\n",
    "            target_class_acc = 0.0\n",
    "            print(f'No samples found for class {target_class}.')\n",
    "            \n",
    "        if analysis:\n",
    "          print('check acc', type(stack_predicts), type(stack_labels))\n",
    "          confusion(stack_predicts, stack_labels)\n",
    "          incorrect_preds(preds, y, x)\n",
    "        return float(acc)\n",
    "\n",
    "        \n",
    "\n",
    "def train_part(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on food101 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters of the model using the gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch: %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "        check_accuracy(loader_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q_6N1VZQuW58",
    "outputId": "f6f297e1-c358-4908-b2ce-be50984945a5",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# define and train the network\n",
    "model = MyResNet()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.0001, weight_decay=1e-7) \n",
    "\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "\n",
    "train_part(model, optimizer, epochs = 10)\n",
    "\n",
    "\n",
    "# report test set accuracy\n",
    "check_accuracy(loader_val, model, analysis=True)\n",
    "\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the saved weights into the model\n",
    "model = MyResNet()\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model = model.to(device=device)  # move the model parameters to CPU/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Network Performance\n",
    "\n",
    "Run the code below when all engineering decisions have been made, do not overfit to the test set!\n",
    "\n",
    "**Note that** this will appear in the output, and be checked by markers (so ensure it is present in the auto-export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "editable": false,
    "id": "m-GqMA0VoHxj",
    "outputId": "3ac2a052-8302-49c7-f6ee-913a24abe335",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Run once your have trained your final model\n",
    "check_accuracy(loader_test, model, analysis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q2.1: Engineering Decisions \n",
    "\n",
    "Detail which engineering decisions you made to boost the performance of the baseline results. Note that you are not required to implement all of them and some in the list below are pointless. One or two reasonable choices are sufficient to reach all points, we are only looking for minor improvements. (12 points for improving performance, 22 points for the soundness of adaptations made)\n",
    "\n",
    "### Select valid engineering decisions that were made to improve the baseline results for the custom deep learning model. Tick all that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- [ ] 1. Data augmentation was used to increase the size and diversity of the training dataset.\n",
    "- [ ] 2. Implemented a custom ResNet variant similar in depth to ResNet50.\n",
    "- [ ] 3. LeakyReLU activation was chosen to address the Dying ReLU problem.\n",
    "- [ ] 4. Randomized search was used to tune hyperparameters, testing 20 combinations.\n",
    "- [ ] 5. A k-fold cross-validation randomized search was used for hyperparameter tuning.\n",
    "- [ ] 6. A cosine annealing learning rate scheduler was used to improve accuracy.\n",
    "- [ ] 7. The best weight decay value was found to be <fill in>.\n",
    "- [ ] 8. The optimal batch size for training was <fill in>.\n",
    "- [ ] 9. Dropout was used extensively to improve regularization.\n",
    "- [ ] 10. Batch normalization was used instead of dropout for regularization.\n",
    "- [ ] 11. Early stopping was implemented to prevent overfitting.\n",
    "- [ ] 12. The model achieved <fill in>% accuracy on the validation set after training for <fill in> epochs.\n",
    "- [ ] 13. The learning rate was kept constant throughout training.\n",
    "- [ ] 14. ImageNet AutoAugment was used for data augmentation.\n",
    "- [ ] 15. Data augmentation transformations were manually defined.\n",
    "- [ ] 16. The final model architecture included max pooling layers after each convolutional block.\n",
    "- [ ] 17. Global average pooling was used in the final layer instead of max pooling.\n",
    "- [ ] 18. The training dataset was expanded to include 200 additional classes.\n",
    "- [ ] 19. Increasing the number of epochs improved model accuracy without overfitting.\n",
    "- [ ] 20. The model achieved a plateau in validation accuracy, indicating overfitting.\n",
    "- [ ] 21. The labels were converted to binary classification (Hot Dog/No Hot Dog) to improve only Hot Dog detection accuracy. \n",
    "\n",
    "\n",
    "New accuracy after extension: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q2.2: Out of distribution evaluation\n",
    "\n",
    "Lets see how your trained model performs on a custom hot dog detection dataset. Do not try and modify your model to perform well on this task, this is just a reflective exercise. How did your model perform at the task? Why do you think this was the case? Detail one method which you expect would improve model performance. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "from icl_dl_cw2_utils.utils.hotdogdataset import DLHotDogDataset\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "image_size_ = 256\n",
    "batch_size = 128\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]) # assuming same dist as imagenet\n",
    "std = torch.Tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean.tolist(), std.tolist()),\n",
    "        ]\n",
    "\n",
    "    )\n",
    "\n",
    "synth_hotdog_dataset = DLHotDogDataset(root=content_path, transform=transform, split='test', preload=True)\n",
    "\n",
    "print(len(synth_hotdog_dataset))\n",
    "\n",
    "synth_hotdog_loader = DataLoader(synth_hotdog_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "sample_inputs, _ = next(iter(synth_hotdog_loader))\n",
    "fixed_input = sample_inputs[:27, :, :, :]\n",
    "\n",
    "img = make_grid(denorm(fixed_input), nrow=9, padding=2, normalize=False,\n",
    "                value_range=None, scale_each=False, pad_value=0)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis('off')\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "check_accuracy(synth_hotdog_loader, model, analysis=True, hotdog_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nytiCnC2uW5_"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Part 3 (11 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code provided below will allow you to visualise the feature maps computed by different layers of your network. Run the code (install matplotlib if necessary) and *answer the following questions*: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q3.1 : Learned Features\n",
    "\n",
    "Compare the feature maps from low-level layers to high-level layers, what do you observe? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Visualization**\n",
    "\n",
    "The code below will visualize the features of your network layers (you may need to modify the layer names if you made changes to your architecture). \n",
    "\n",
    "If you change the plotting code, please ensure it still exports correctly when running the submission cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_features():\n",
    "    fig = plt.tight_layout()\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    vis_labels = ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'layer5', 'layer6']\n",
    "\n",
    "    for l in vis_labels:\n",
    "        getattr(model, l).register_forward_hook(get_activation(l))\n",
    "        \n",
    "\n",
    "    data, _ = test_dataset[999]\n",
    "    data = data.unsqueeze_(0).to(device = device, dtype = dtype)\n",
    "    output = model(data)\n",
    "\n",
    "    for idx, l in enumerate(vis_labels):\n",
    "        act = activation[l].squeeze()\n",
    "\n",
    "        # only showing the first 16 channels\n",
    "        ncols, nrows = 8, 2\n",
    "        \n",
    "        fig, axarr = plt.subplots(nrows, ncols, figsize=(15,5))\n",
    "        fig.suptitle(l)\n",
    "\n",
    "        count = 0\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                axarr[i, j].imshow(act[count].cpu())\n",
    "                axarr[i, j].axis('off')\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pxJhnmxnuW6B",
    "outputId": "6afa5801-d603-47aa-be17-cf7329fc352a",
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the figure here, so it is exported nicely\n",
    "plot_model_features()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q3.2: Performance Analysis\n",
    "\n",
    "Use the training log, reported test set accuracy and the feature maps, analyse the performance of your network. If you think the performance is sufficiently good, explain why; if not, what might be the problem and how can you improve the performance? (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Submission\n",
    "Git push your finalized version of this notebook (with saved outputs) to the gitlab repo which you were assigned. You should request our tests once and check that the ```preview.pdf```:\n",
    "* Passes all public tests (these are the same ones provided / embedded in the notebook itself)\n",
    "* Contains your qualitative answers\n",
    "* Contains your figures (confusion matrix and network features)\n",
    "\n",
    "You do not need to include OTTER_LOG in the submitted files, as we will run all the tests from scratch on the LabTS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "460cw1_2022_sample_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "otter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "BatchNorm Layer": {
     "name": "BatchNorm Layer",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(BatchNorm2d(2)(torch.zeros((3, 2, 7, 6))).shape) == [3, 2, 7, 6]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(BatchNorm2d(2)(torch.zeros((3, 2, 7, 6)))) == torch.Tensor\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        },
        {
         "code": ">>> hasattr(BatchNorm2d(2), 'gamma') and hasattr(BatchNorm2d(2), 'beta')\nTrue",
         "failure_message": "Param Name Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Name Test Passed"
        },
        {
         "code": ">>> layer = BatchNorm2d(7)\n>>> list(torch.squeeze(layer.gamma).shape) == [7] and list(torch.squeeze(layer.beta).shape) == [7]\nTrue",
         "failure_message": "Param Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Shape Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Convolution Layer": {
     "name": "Convolution Layer",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(Conv2d(3, 7, 9)(torch.zeros((10, 3, 64, 64))).shape) == [10, 7, 56, 56]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(Conv2d(1, 3, 2)(torch.zeros((7, 1, 32, 32)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        },
        {
         "code": ">>> hasattr(Conv2d(1, 1, 1), 'w') and hasattr(Conv2d(1, 1, 1), 'b')\nTrue",
         "failure_message": "Param Name Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Name Test Passed"
        },
        {
         "code": ">>> layer = Conv2d(7, 32, 4)\n>>> list(layer.w.shape) == [32, 7, 4, 4] and list(layer.b.shape) == [32]\nTrue",
         "failure_message": "Param Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Shape Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Linear Layer": {
     "name": "Linear Layer",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(Linear(25, 28)(torch.zeros((17, 25))).shape) == [17, 28]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(Linear(13, 15)(torch.zeros((6, 13)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        },
        {
         "code": ">>> hasattr(Linear(2, 2), 'w') and hasattr(Linear(2, 2), 'b')\nTrue",
         "failure_message": "Param Name Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Name Test Passed"
        },
        {
         "code": ">>> layer = Linear(13, 24)\n>>> list(layer.w.shape) in [[13, 24], [24, 13]] and list(layer.b.shape) == [24]\nTrue",
         "failure_message": "Param Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Shape Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "MaxPool Layer": {
     "name": "MaxPool Layer",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(MaxPool2d(3)(torch.zeros((10, 3, 64, 64))).shape) == [10, 3, 21, 21]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(MaxPool2d(3)(torch.zeros((10, 3, 64, 64)))) in [torch.Tensor]\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
